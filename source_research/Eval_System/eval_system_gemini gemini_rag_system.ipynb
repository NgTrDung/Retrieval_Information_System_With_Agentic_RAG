{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257c16cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hghaan/rerank_model\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "project_path = r\"D:/DaiHoc/machinelearning/TLCN/DoAnTotNghiep_chat_bot/\"\n",
    "sys.path.append(project_path)\n",
    "from source.function.utils_result import RAG\n",
    "from source.search.utils_search import Qdrant_Utils\n",
    "from source.rerank.utils_rerank import Rerank_Utils  \n",
    "from source.model.embedding_model import Sentences_Transformer_Embedding\n",
    "from source.model.extract_model import Bert_Extract\n",
    "from source.model.generate_model import Gemini\n",
    "from source.model.rerank_model import Cohere\n",
    "from source.data.vectordb.qdrant import Qdrant_Vector\n",
    "from source.core.config import Settings\n",
    "from source.model.rerank_model_finetune import RerankModelFinetune\n",
    "from source.generate.generate import Gemini_Generate\n",
    "from source.extract.utils_extract import Extract_Information\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "setting=Settings()\n",
    "gemini=Gemini(setting)\n",
    "print(setting.RERANK)\n",
    "cohere_api=Cohere(setting)\n",
    "bert=Bert_Extract(setting)\n",
    "rerank_model_fintuned=RerankModelFinetune(setting)\n",
    "sentences_transformer_embedding=Sentences_Transformer_Embedding(setting)\n",
    "qdrant=Qdrant_Vector(setting,sentences_transformer_embedding)\n",
    "rerank_Utils=Rerank_Utils(cohere_api,rerank_model_fintuned)\n",
    "extract_Utils= Extract_Information(bert)\n",
    "generate_Utils=Gemini_Generate(gemini,setting)\n",
    "qdrant_Utils=Qdrant_Utils(qdrant, generate_Utils)\n",
    "rag=RAG(generate_Utils,extract_Utils,qdrant_Utils,rerank_Utils,setting,sentences_transformer_embedding)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hghaan/rerank_model\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "project_path = r\"D:/DaiHoc/machinelearning/TLCN/DoAnTotNghiep_chat_bot/\"\n",
    "sys.path.append(project_path)\n",
    "from source.function.utils_result import RAG\n",
    "from source.search.utils_search import Qdrant_Utils\n",
    "from source.rerank.utils_rerank import Rerank_Utils  \n",
    "from source.model.embedding_model import Sentences_Transformer_Embedding\n",
    "from source.model.extract_model import Bert_Extract\n",
    "from source.model.generate_model import Gemini\n",
    "from source.model.rerank_model import Cohere\n",
    "from source.data.vectordb.qdrant import Qdrant_Vector\n",
    "from source.core.config import Settings\n",
    "from source.model.rerank_model_finetune import RerankModelFinetune\n",
    "from source.generate.generate import Gemini_Generate\n",
    "from source.extract.utils_extract import Extract_Information\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "setting=Settings()\n",
    "gemini=Gemini(setting)\n",
    "print(setting.RERANK)\n",
    "cohere_api=Cohere(setting)\n",
    "bert=Bert_Extract(setting)\n",
    "rerank_model_fintuned=RerankModelFinetune(setting)\n",
    "sentences_transformer_embedding=Sentences_Transformer_Embedding(setting)\n",
    "qdrant=Qdrant_Vector(setting,sentences_transformer_embedding)\n",
    "rerank_Utils=Rerank_Utils(cohere_api,rerank_model_fintuned)\n",
    "extract_Utils= Extract_Information(bert)\n",
    "generate_Utils=Gemini_Generate(gemini,setting)\n",
    "qdrant_Utils=Qdrant_Utils(qdrant, generate_Utils)\n",
    "rag=RAG(generate_Utils,extract_Utils,qdrant_Utils,rerank_Utils,setting,sentences_transformer_embedding)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d5d7",
   "metadata": {},
   "source": [
    "## 1.Eval Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7218d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file CSV chứa câu hỏi và câu trả lời đã có (nếu có)\n",
    "df = pd.read_csv('./data/data_processed/final_data_system_response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4031e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern = r'Xin\\s+lỗi\\s+bạn'  # regex cho “Xin lỗi bạn” (có thể có nhiều khoảng trắng)\n",
    "\n",
    "# Chỉ giữ lại những dòng không khớp pattern\n",
    "df = df[~df['answer_from_gemini_rag_basic'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67cffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['answer_from_gemini_rag_final'].str.contains(pattern, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5a9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['answer_from_gemini_rag_final'].str.contains(r'\"\"', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23388ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87605d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6ccc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abb9a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sinh trả lời:   0%|          | 0/564 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sinh trả lời:  37%|███▋      | 207/564 [1:05:14<5:52:34, 59.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: status_code: 502, body: \n",
      "<html><head>\n",
      "<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n",
      "<title>502 Server Error</title>\n",
      "</head>\n",
      "<body text=#000000 bgcolor=#ffffff>\n",
      "<h1>Error: Server Error</h1>\n",
      "<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>\n",
      "<h2></h2>\n",
      "</body></html>\n",
      "\n",
      "\n",
      "❌ Lỗi tại index 206 (DataFrame index = 206):\n",
      "Một số gia đình khi thuê người giúp việc gia đình vẫn thường than phiền khi tết đến phải cho người giúp việc tiền tàu xe, còn sợ sau tết họ lại bỏ việc. Đề nghị cho biết pháp luật quy định về vấn đề này như thế nào?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sinh trả lời: 100%|██████████| 564/564 [2:52:13<00:00, 18.32s/it]  \n"
     ]
    }
   ],
   "source": [
    "def Generate_Response(df_batch):\n",
    "    answers = []\n",
    "    for idx, question in tqdm(list(enumerate(df_batch['question'])), desc=\"Sinh trả lời\"):\n",
    "        try:\n",
    "            article_doc = rag.get_gemini_response_rag_final(question)\n",
    "            answers.append(article_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Lỗi tại index {idx} (DataFrame index = {df_batch.index[idx]}):\\n{question}\")\n",
    "            answers.append(\"\")\n",
    "    return answers\n",
    "\n",
    "\n",
    "df['answer_from_gemini_rag_final'] = Generate_Response(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51edd72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã cập nhật và lưu toàn bộ vào: ./data/data_processed/final_data_system_response.csv\n"
     ]
    }
   ],
   "source": [
    "final_output_path = './data/data_processed/final_data_system_response.csv'\n",
    "df.to_csv(final_output_path, index=False)\n",
    "print(f\" Đã cập nhật và lưu toàn bộ vào: {final_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c857fd",
   "metadata": {},
   "source": [
    "> Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd43c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting=Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99561e",
   "metadata": {},
   "source": [
    "> Get embedding gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a4e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=gemini.key_manager.get_next_key())\n",
    "\n",
    "def get_gemini_embedding(texts):\n",
    "    try :\n",
    "        result = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=texts,\n",
    "            task_type=\"SEMANTIC_SIMILARITY\"\n",
    "        )\n",
    "        \n",
    "        return result['embedding']\n",
    "    except Exception as e:\n",
    "        print(\"Đã xảy ra lỗi:\", e)\n",
    "        return [0.0] * 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd6dbd",
   "metadata": {},
   "source": [
    "> get embedding cohere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06167d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "def get_cohere_embedding(text: str, model_name: str = \"embed-v4.0\") -> list:\n",
    "    try:\n",
    "        co = cohere.ClientV2(api_key=cohere_api.key_manager.get_next_key())\n",
    "        res = co.embed(\n",
    "            texts=[text],\n",
    "            model=model_name,\n",
    "            input_type=\"classification\",\n",
    "            embedding_types=[\"float\"],\n",
    "        )\n",
    "\n",
    "        # Trả về nhúng đầu tiên\n",
    "        return res.embeddings.float[0]\n",
    "    except Exception as e:\n",
    "        print(\"Đã xảy ra lỗi:\", e)\n",
    "        return [0.0] * 1024  # Trả về danh sách 1024 số 0 nếu có lỗi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6189d6",
   "metadata": {},
   "source": [
    ">Get  rouge-L & F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251b6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def compute_rouge_l(pred: str, ref: str) -> float:\n",
    "    try:\n",
    "        score = scorer.score(ref, pred)\n",
    "        return score['rougeL'].fmeasure\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def compute_f1(pred: str, ref: str) -> float:\n",
    "    pred_tokens = pred.lower().split()\n",
    "    ref_tokens = ref.lower().split()\n",
    "    common = set(pred_tokens) & set(ref_tokens)\n",
    "    if not pred_tokens or not ref_tokens:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(ref_tokens)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2863838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa0009fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xảy ra lỗi: 400 Request payload size exceeds the limit: 36000 bytes.\n",
      "Đã xảy ra lỗi: 400 Request payload size exceeds the limit: 36000 bytes.\n"
     ]
    }
   ],
   "source": [
    "# df['answer_embedding_cohere'] = df['answer'].apply(get_cohere_embedding)\n",
    "# df['answer_from_gemini_rag_final_cohere'] = df['answer_from_gemini_rag_final'].apply(get_cohere_embedding)\n",
    "\n",
    "\n",
    "df['answer_embedding'] = df['answer'].apply(get_gemini_embedding)\n",
    "df['answer_from_gemini_rag_final_embedding'] = df['answer_from_gemini_rag_final'].apply(get_gemini_embedding)\n",
    "\n",
    "df['cosine_similarity_gemini_rag_final'] = df.apply(\n",
    "    lambda row: cosine_similarity(\n",
    "        [row['answer_embedding']], \n",
    "        [row['answer_from_gemini_rag_final_embedding']]\n",
    "    )[0][0],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# df['cosine_similarity_cohere'] = df.apply(\n",
    "#     lambda row: cosine_similarity(\n",
    "#         [row['answer_embedding_cohere']], \n",
    "#         [row['answer_from_gemini_rag_final_cohere']]\n",
    "#     )[0][0],\n",
    "#     axis=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c5bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rouge_l'] = df.apply(lambda row: compute_rouge_l(row['answer_from_gemini_rag_final'], row['answer']), axis=1)\n",
    "df['f1'] = df.apply(lambda row: compute_f1(row['answer_from_gemini_rag_final'], row['answer']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95c6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trung bình Cosine (Gemini): 0.9012\n",
      " Trung bình ROUGE-L: 0.4076\n",
      " Trung bình F1 Score: 0.2233\n"
     ]
    }
   ],
   "source": [
    "print(f\" Trung bình Cosine (Gemini): {df['cosine_similarity_gemini_rag_final'].mean():.4f}\")\n",
    "print(f\" Trung bình ROUGE-L: {df['rouge_l'].mean():.4f}\")\n",
    "print(f\" Trung bình F1 Score: {df['f1'].mean():.4f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLCN-KU7o-pax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
